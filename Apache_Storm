import org.apache.storm.Config;
import org.apache.storm.LocalCluster;
import org.apache.storm.topology.TopologyBuilder;
import org.apache.storm.kafka.spout.*;
import org.apache.storm.kafka.bolt.KafkaBolt;
import org.apache.storm.kafka.bolt.mapper.FieldNameBasedTupleToKafkaMapper;
import org.apache.storm.kafka.bolt.selector.DefaultTopicSelector;
import org.apache.storm.tuple.Fields;

public class JavaStormApp {
    public static void main(String[] args) {
        // Create a topology builder
        TopologyBuilder builder = new TopologyBuilder();
        
        // Configure Kafka Spout
        KafkaSpout<String, String> kafkaSpout = new KafkaSpout<>(KafkaSpoutConfig.builder("localhost:9092", "kafka-topic").build());
        
        // Add Kafka Spout to the topology
        builder.setSpout("kafka-spout", kafkaSpout);
        
        // Add bolt for processing Kafka messages
        builder.setBolt("process-bolt", new ProcessBolt()).shuffleGrouping("kafka-spout");
        
        // Configure and submit the topology
        Config config = new Config();
        LocalCluster cluster = new LocalCluster();
        cluster.submitTopology("kafka-processing-topology", config, builder.createTopology());
    }
}

And here's a simple bolt class ProcessBolt that processes the incoming messages:

import org.apache.storm.topology.BasicOutputCollector;
import org.apache.storm.topology.base.BaseRichBolt;
import org.apache.storm.tuple.Fields;
import org.apache.storm.tuple.Tuple;
import org.apache.storm.tuple.Values;

public class ProcessBolt extends BaseRichBolt {
    @Override
    public void execute(Tuple tuple, BasicOutputCollector collector) {
        // Get the message value from the tuple
        String message = tuple.getStringByField("value");
        
        // Split the message into words
        String[] words = message.split(" ");
        
        // Emit each word with count 1
        for (String word : words) {
            collector.emit(new Values(word, 1));
        }
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        // Declare output fields
        declarer.declare(new Fields("word", "count"));
    }
}


In this Storm topology:

We configure a Kafka spout to consume messages from the "kafka-topic" Kafka topic.
Messages are then processed by a bolt (ProcessBolt) which splits them into words and emits each word with a count of 1.
This word-count data can then be further processed or persisted as needed.

Maven dependency for Apache Storm:

<dependency>
    <groupId>org.apache.storm</groupId>
    <artifactId>storm-core</artifactId>
    <version>2.2.0</version> <!-- Replace with the desired version -->
</dependency>

<dependency>
    <groupId>org.apache.storm</groupId>
    <artifactId>storm-kafka-client</artifactId>
    <version>2.2.0</version> <!-- Replace with the version compatible with your Storm version -->
</dependency>




