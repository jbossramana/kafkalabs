

{
    "name": "jdbc_source_mysql_foobar_01",
    "config": {
        "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
        "key.converter": "io.confluent.connect.avro.AvroConverter",
        "key.converter.schema.registry.url": "http://localhost:8081",
        "value.converter": "io.confluent.connect.avro.AvroConverter",
        "value.converter.schema.registry.url": "http://localhost:8081",
        "connection.url": "jdbc:mysql://localhost:3306/demo?user=kafka&password=kafka",
        "table.whitelist": "table1, table2", // Add both tables here separated by commas
        "mode": "incrementing",
        "incrementing.column.name": "id", // Assuming you have an incrementing column for both tables
        "validate.non.null": "false",
        "topic.prefix": "mysql-",
         "transforms": "createKey,extractInt",
        "transforms.createKey.type": "org.apache.kafka.connect.transforms.ValueToKey",
        "transforms.createKey.fields": "id",
        "transforms.extractInt.type": "org.apache.kafka.connect.transforms.ExtractField$Key",
        "transforms.extractInt.field": "id"

    }
}



Assume we have two tables in the MySQL database:

Table 1: table1

id	name	age
101	John	25
102	Alice	30
103	Bob	28
Table 2: table2

id	department	salary
201	HR	50000
202	IT	60000
203	Finance	55000


After configuring the JDBC Source Connector with the provided configuration, the connector will read the data from these tables and write it to Kafka topics. Let's say the Kafka topics are named 
mysql-table1 and mysql-table2 (prefixed with "mysql-" as specified in the configuration).


The output in Kafka topics would look like this:

Kafka topic mysql-table1:

Key: 101, Value: {"id":101,"name":"John","age":25}
Key: 102, Value: {"id":102,"name":"Alice","age":30}
Key: 103, Value: {"id":103,"name":"Bob","age":28}

Kafka topic mysql-table2:

Key: 201, Value: {"id":201,"department":"HR","salary":50000}
Key: 202, Value: {"id":202,"department":"IT","salary":60000}
Key: 203, Value: {"id":203,"department":"Finance","salary":55000}


Each message in Kafka contains a key and a value. In this case, the key is extracted from the "id" field of each table, as specified in the transformation configuration. The value is a JSON object 
representing the corresponding row data from the tables.








